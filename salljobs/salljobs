#!/usr/bin/python

import sys
from collections import defaultdict
from pwd import getpwnam, getpwuid

import argparse

try:
    import pyslurm
except ImportError:
    sys.exit("You need to install PySlurm: https://github.com/PySlurm/pyslurm")

__author__ = "Giovanni Torres"
__date__ = "Fri Aug 21 12:59:28 EST 2015"

# Print formatting for -u (by user)
HEADER_FORMAT = "                     {0:^23}    {1:^15}"
LINE_FORMAT = "{0:>20} {1:>7} {2:>7} {3:>7}    {4:>7} {5:>7}"

# Print formatting for -p (by partition)
LINE_FORMAT_P1 = "{0:<20} {1:>13} {2:>7} {3:>7} {4:>7} {5:>7}"
LINE_FORMAT_P2 = "{0:>34} {1:>7} {2:>7} {3:>7} {4:>7}"

# SLURM job states
STATES = {"PENDING": "PD",          # queued, waiting for initiation
          "RUNNING": "R",           # allocated resources and executing
          "CANCELLED": "CA",        # cancelled by user
          "CONFIGURING": "CF",      # allocated nodes booting
          "COMPLETING": "CG",       # waiting for epilog completion
          "COMPLETED": "CD",        # completed execution successfully
          "FAILED": "F",            # completed execution unsuccessfully
          "TIMEOUT": "TO",          # terminated on reaching time limit
          "NODE_FAIL": "NF",        # terminated on node failure
          "PREEMPTED": "PR",        # terminated due to preemption
          "SUSPENDED": "S",         # allocated resources, execution suspended
          "SPECIAL_EXIT": "SE"}     # requeue an exit job in hold

def sum_pending(array_tasks):
    """
    Return number of subjobs for pending job array. This notation
    can be pretty involved:
          31392108_[1,3,5]
          31392313_[1,3,5%2]
          31392415_[1-5]
    """
    # remove a possible '%...' part
    subjobstr = array_tasks.split("%")[0]
    # split into chunks
    chunks = subjobstr.split(",")
    n = 0
    for chunk in chunks:
        if "-" not in array_tasks:
            n += 1
        else:
            start, end = chunk.split("-")
            n += int(end) - int(start) + 1
    return n

def rehash_job_dict(jobs):
    """
    rehash job dict to be keyed by username
    """
    new_dict = defaultdict(list)
    for key, value in jobs.items():
        user_id = value.get("user_id")
        user_name = getpwuid(user_id)[0]
        new_dict[user_name].append(value)

    return new_dict

def display_by_user(userlist, all_nodes, all_jobs):
    """
    Display a list of all jobs, by default, formatted by user with the -u
    option.  The -u option can take a space separated list of one or more
    users.
    Pending jobs don't include NODES - it just doesn't really make sense
    especially for jobs smaller than single nodes.
    """

    print ""
    print HEADER_FORMAT.format("RUNNING", "PENDING")
    print HEADER_FORMAT.format("-" * 23, "-" * 15)
    print LINE_FORMAT.format("USERNAME", "CPUS", "NODES", "JOBS",
                             "CPUS", "JOBS")

    total_procs_request = 0
    total_procs_used = 0
    total_nodes_used = 0
    total_job_running = 0
    total_job_pending = 0

    rehashed_jobs = rehash_job_dict(all_jobs)

    for user in sorted(userlist):

        try:
            user_jobs = rehashed_jobs[user]
        except KeyError:
            continue

        procs_request = 0
        procs_used = 0
        nodes_used = set()
        running = 0
        pending = 0

        if user_jobs is None:
            continue

        for job in user_jobs:
            if job["job_state"] == "PENDING":
                # If a job is pending, get the total number of pending subjobs,
                # instead of counting it as just a single pending job.  For
                # example, a pending swarm could have a 100 pending subjobs
                #
                # also: pending jobs may request CPUs in any increment but
                # slurm does necessarily allocate in single CPU increments. It
                # may allocate CPU, core, socket, or whole node increments. Since
                # the final allocated CPU number could vary for identical pending
                # jobs (if the, for example, ended up on hyperthreading vs non-hyperthreading
                # nodes.
                if job.get("array_task_str") is not None:
                    n = sum_pending(job["array_task_str"])
                    pending += n
                    procs_request += job["num_cpus"] * n
                else:
                    pending += 1
                    procs_request += job["num_cpus"]
            else:
                running += 1
                procs_used += job["num_cpus"]
                nodes_alloc = job["cpus_allocated"].keys()
                nodes_used.update(nodes_alloc)

        total_procs_request += procs_request
        total_procs_used += procs_used
        total_job_running += running
        total_job_pending += pending

        print LINE_FORMAT.format(user,
                                 procs_used,
                                 len(nodes_used),
                                 running,
                                 procs_request,
                                 pending)

    # If one or more users are not specified, print a TOTAL summary
    if not args.user:
        used_nodes = get_used_nodes(all_nodes)
        total_cpus, total_nodes = get_total_cpus_and_nodes(all_nodes)

        print HEADER_FORMAT.format("-" * 23, "-" * 15)
        print LINE_FORMAT.format("TOTAL",
                                 str(total_procs_used),
                                 str(used_nodes),
                                 total_job_running,
                                 total_procs_request,
                                 total_job_pending)


        print LINE_FORMAT.format("AVAILABLE",
                                 str(total_cpus),
                                 str(total_nodes), "", "", "", "")
    pending_cpu_note()
    print ""

def pending_cpu_note():
    print ""
    print "The number of CPUs for PENDING jobs is a minimal estimate."
    print "Actual allocation may be different."


def display_by_partition(jobs, partlist, userlist):
    """
    Display a list of all jobs formatted by partition with the -p
    option.  The -p option can take a space separated list of one or more
    partitions.
    """

    if userlist is None:
        # If users are not specified at the command line with the -p option,
        # get all users
        userset = set(value["user_id"]
                      for value in jobs.values())
        users = [getpwuid(user)[0] for user in userset]
    else:
        users = userlist

    print LINE_FORMAT_P1.format("USERNAME", "PARTITION", "STATE", "CPUS", "NODES", "JOBS")
    print ""

    # Define default nested dictionaries for totals that take either an int or
    # a set as a default value
    cluster_totals_bypart = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
    cluster_totals_bystate = defaultdict(lambda: defaultdict(int))
    total_nodes_used = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))

    rehashed_jobs = rehash_job_dict(jobs)

    for user in sorted(users):

        # Define default nested dictionaries for per-user totals that take
        # either an int or a set as a default value
        user_totals = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
        nodes_used = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))
        user_jobs = rehashed_jobs.get(user)

        if user_jobs is None:
            print "User has no running jobs."
            sys.exit(1)

        for job in user_jobs:
            partition = job["partition"]
            if partlist is None or partition in partlist:
                job_state = job["job_state"]
                cpus = job["num_cpus"]
                nodes_alloc = job["cpus_allocated"].keys()
                nodes_used[partition][job_state]["node_set"].update(nodes_alloc)
                total_nodes_used[partition][job_state]["node_set"].update(nodes_alloc)

                if job_state == "PENDING":
                    # If a job is pending, get the total number of pending subjobs,
                    # instead of counting it as just a single pending job.  For
                    # example, a pending swarm could have a 100 pending subjobs
                    if job.get("array_task_str") is not None:
                        n = sum_pending(job["array_task_str"])
                        user_totals[partition][job_state]["jobs"] += n
                        user_totals[partition][job_state]["cpus"] += cpus * n
                    else:
                        user_totals[partition][job_state]["jobs"] += 1
                        user_totals[partition][job_state]["cpus"] += cpus
                else:
                    user_totals[partition][job_state]["jobs"] += 1
                    user_totals[partition][job_state]["cpus"] += cpus

        line_counter = 0

        for part, states in sorted(user_totals.items()):
            for state, totals in reversed(sorted(states.items())):
                cluster_totals_bypart[part][state]["jobs"] += totals["jobs"]
                cluster_totals_bypart[part][state]["cpus"] += totals["cpus"]

                if state == "PENDING":
                    nnodes = "N/A"
                else:
                    nnodes = len(nodes_used[part][state]["node_set"])

                if line_counter == 0:
                    print LINE_FORMAT_P1.format(user,
                                                part,
                                                STATES[state],
                                                totals["cpus"],
                                                nnodes,
                                                totals["jobs"])
                else:
                    print LINE_FORMAT_P2.format(part,
                                                STATES[state],
                                                totals["cpus"],
                                                nnodes,
                                                totals["jobs"])
                line_counter += 1

    print ""
    print "SUMMARY BY PARTITION"

    print LINE_FORMAT_P2.format("PARTITION", "STATE", "CPUS", "NODES", "JOBS")

    for c_part, c_states in sorted(cluster_totals_bypart.iteritems()):
        c_line_counter = 0
        for c_state, c_totals in reversed(sorted(c_states.iteritems())):
            cluster_totals_bystate[c_state]["jobs"] += c_totals["jobs"]
            cluster_totals_bystate[c_state]["cpus"] += c_totals["cpus"]
            sum_nodes = len(total_nodes_used[c_part][c_state]["node_set"])
            cluster_totals_bystate[c_state]["sum_nodes"] += sum_nodes
            if c_state == "PENDING":
                sum_nodes = "N/A"

            if c_line_counter == 0:
                print LINE_FORMAT_P2.format(c_part,
                                          STATES[c_state],
                                          c_totals["cpus"],
                                          sum_nodes,
                                          c_totals["jobs"])
            else:
                print LINE_FORMAT_P2.format("",
                                          STATES[c_state],
                                          c_totals["cpus"],
                                          sum_nodes,
                                          c_totals["jobs"])
            c_line_counter += 1

    print ""
    print "SUMMARY BY STATE"

    print LINE_FORMAT_P2.format("", "STATE", "CPUS", "NODES", "JOBS")

    for cs_state, cs_values in reversed(sorted(cluster_totals_bystate.items())):
        if cs_state == "PENDING":
            nnodes = "N/A"
        else:
            nnodes = cs_values["sum_nodes"]
        print LINE_FORMAT_P2.format("",
                                  STATES[cs_state],
                                  cs_values["cpus"],
                                  nnodes,
                                  cs_values["jobs"])
    pending_cpu_note()


def get_used_nodes(nodelist):
    """Return number of used nodes, i.e. those in the MIXED or ALLOCATED
       states."""
    return len([node for node, values in nodelist.iteritems()
                if values['state'] == "ALLOCATED"
                or values['state'] == "MIXED"])


def get_total_cpus_and_nodes(nodelist):
    """
    Return total number of available CPUs and nodes.
    Those nodes in the Down and Drain* states are not counted
    in the totals.
    """
    tmp = [values['cpus'] for values in nodelist.values()
                if not any(_ in values["state"]
                           for _ in ("DOWN", "DRAIN"))]
    return sum(tmp), len(tmp)


def check_users(users):
    """
    Slurm reports numeric user ids.  This function checks to see if the user
    is in /etc/passwd, i.e. a valid user.  If not, exit with unknown user
    message.
    """
    for user in users:
        try:
            usertest = getpwnam(user)
        except KeyError:
            print "Username (%s) not found." % user
            sys.exit(1)

def get_jobs(user=None):
    if user is None:
        try:
            jobs = pyslurm.job().get()
        except ValueError as e:
            print 'Query failed - %s' % (e)
            sys.exit(1)
        else:
            return jobs
    else:
        jobs = {}
        try:
            for u in user:
                jobs.update(pyslurm.job().find_user(u))
        except ValueError as e:
            print 'Query failed - %s' % (e)
            sys.exit(1)
        else:
            return jobs


def get_nodes():
    try:
        nodes = pyslurm.node().get()
    except ValueError as e:
        print 'Query failed - %s' % (e)
        sys.exit(1)
    else:
        return nodes


if __name__ == "__main__":
    # Set up command line arguments
    description = "Query user jobs"
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument("-u", help="query by user(s) (space separated)",
                        nargs="+", dest="user")
    parser.add_argument("-p", help="query by partition(s) (space separated)",
                        nargs="*", dest="part")
    args = parser.parse_args()

    # -p
    if args.part == [] and args.user is None:
        jobs = get_jobs()
        display_by_partition(jobs, partlist=None, userlist=None)
    # -p part
    elif args.part is not None and args.user is None:
        jobs = get_jobs()
        partlist = args.part
        display_by_partition(jobs, partlist=partlist, userlist=None)
    # -p -u user
    elif args.part == [] and args.user is not None:
        check_users(args.user)
        userlist = args.user
        jobs = get_jobs(userlist)
        display_by_partition(jobs, partlist=None, userlist=userlist)
    # -p part -u user
    elif args.part is not None and args.user is not None:
        check_users(args.user)
        partlist = args.part
        userlist = args.user
        jobs = get_jobs(userlist)
        display_by_partition(jobs, partlist=partlist, userlist=userlist)
    # -u user
    elif args.user:
        users = args.user
        check_users(users)
        jobs = get_jobs(users)
        nodes = get_nodes()
        display_by_user(users, nodes, jobs)
    # if no command-line arguments given, only show users that have at least
    # running and or pending jobs.  These users may also have jobs in other
    # transitional states.
    else:
        jobs = get_jobs()
        nodes = get_nodes()
        userset = set(value["user_id"]
                      for value in jobs.itervalues()
                      if value["job_state"] == "RUNNING"
                      or value["job_state"] == "PENDING")
        users = [getpwuid(user)[0] for user in userset]
        display_by_user(users, nodes, jobs)
